{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "%pip install pyreadline\n",
    "%config Completer.use_jedi = False\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy\n",
    "import random\n",
    "from gym import wrappers\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Env_Name='CartPole-v1'\n",
    "\n",
    "Batch_Size=64\n",
    "Replay_Memory_Size=1000000\n",
    "Target_Network_Update_Frequency=10\n",
    "Discount_Factor=0.95\n",
    "Learning_Rate=0.001\n",
    "Initial_Exploration=1.0\n",
    "Final_Exploration=0.005\n",
    "Exploration_Decay=0.9999\n",
    "Episodes=5000\n",
    "Hidden_Layer_Size=256\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device=\",device)\n",
    "\n",
    "env=gym.make(Env_Name)\n",
    "#env=wrappers.Monitor(env,'./tmp/cartpole-v0-0',force=True)\n",
    "#observation=env.reset()\n",
    "\n",
    "Input_Shape=env.observation_space.shape[0]\n",
    "Action_Shape=env.action_space.n\n",
    "#print('Input Shape=',Input_Shape)\n",
    "#print('Action Shape=',Action_Shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self,capacity):\n",
    "        self.capacity=capacity\n",
    "        self.memory=[]\n",
    "    def push(self,transition):\n",
    "        self.memory.append(transition)\n",
    "        if len(self.memory)>self.capacity:\n",
    "            del self.memory[0]\n",
    "    def sample(self,batch_size):\n",
    "        return random.sample(self.memory,batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self,input_shape=4,hidden_layer_shape=Hidden_Layer_Size,action_shape=2):\n",
    "        super(DQN,self).__init__()\n",
    "        self.l1=nn.Linear(input_shape,hidden_layer_shape)\n",
    "        self.l2=nn.Linear(hidden_layer_shape,hidden_layer_shape//2)\n",
    "        self.l3=nn.Linear(hidden_layer_shape//2,hidden_layer_shape//2//2)\n",
    "        self.l4=nn.Linear(hidden_layer_shape//2//2,hidden_layer_shape//2//2//2)\n",
    "        self.l5=nn.Linear(hidden_layer_shape//2//2//2,action_shape)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.l1(x))\n",
    "        x=F.relu(self.l2(x))\n",
    "        x=F.relu(self.l3(x))\n",
    "        x=F.relu(self.l4(x))\n",
    "        x=self.l5(x)\n",
    "        return x\n",
    "\n",
    "# class DQN(nn.Module):\n",
    "#     def __init__(self,input_shape=4,action_shape=2):\n",
    "#         super(DQN,self).__init__()\n",
    "#         self.l1=nn.Linear(input_shape,24)\n",
    "#         self.l2=nn.Linear(24,24)\n",
    "#         self.l3=nn.Linear(24,action_shape)\n",
    "    \n",
    "#     def forward(self,x):\n",
    "#         x=F.relu(self.l1(x))\n",
    "#         x=F.relu(self.l2(x))\n",
    "#         x=self.l3(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=DQN(input_shape=Input_Shape,action_shape=Action_Shape).to(device)\n",
    "\n",
    "\n",
    "memory=ReplayMemory(Replay_Memory_Size)\n",
    "optimizer=optim.Adam(model.parameters(),Learning_Rate)\n",
    "steps_done=0\n",
    "episode_durations=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample=random.random()\n",
    "   # eps_threshold=Final_Exploration+(Initial_Exploration-Final_Exploration)*math.exp(-1.*steps_done/Exploration_Decay)\n",
    "\n",
    "    eps_threshold=Initial_Exploration*Exploration_Decay \n",
    "    eps_threshold=max(eps_threshold,Final_Exploration)\n",
    "    steps_done+=1\n",
    "    if sample>eps_threshold:\n",
    "        return  model(torch.tensor([state],dtype=torch.float32).to(device)).detach().max(1)[1].view(1,1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(2)]],dtype=torch.int64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_episode(e,env):\n",
    "    state=env.reset()\n",
    "    steps=0\n",
    "    while True:\n",
    "        env.render()\n",
    "        action=select_action(state)\n",
    "        next_state,reward,done,_=env.step(action[0,0].item())\n",
    "\n",
    "        if done:\n",
    "            reward=-1\n",
    "\n",
    "        memory.push((torch.tensor([state],dtype=torch.float32).to(device),\n",
    "                    action.clone().detach(),\n",
    "                    torch.tensor([next_state],dtype=torch.float32).to(device),\n",
    "                    torch.tensor([reward],dtype=torch.float32).to(device)))\n",
    "        learn()\n",
    "        state=next_state\n",
    "        steps+=1\n",
    "        if done:\n",
    "            print(\"{2} Episode {0} finished after {1} steps\".format(e,steps,'\\033[92m' if steps>=195\n",
    "                                                                    else '\\033[99m'))\n",
    "            episode_durations.append(steps)\n",
    "            plot_durations()\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn():\n",
    "    if len(memory)<Batch_Size:\n",
    "        return\n",
    "    transitions=memory.sample(Batch_Size)\n",
    "    batch_state,batch_action,batch_next_state,batch_reward=zip(*transitions)\n",
    "    batch_state=(torch.cat(batch_state)).clone().detach()\n",
    "    batch_action=(torch.cat(batch_action)).clone().detach()\n",
    "    batch_next_state=(torch.cat(batch_next_state)).clone().detach()\n",
    "    batch_reward=(torch.cat(batch_reward)).clone().detach()\n",
    "    current_q_values=model(batch_state).gather(1,batch_action)\n",
    "    current_q_values=current_q_values.squeeze(1)\n",
    "    #print(\"current_q_values=\",current_q_values)\n",
    "    \n",
    "    max_next_q_values=model(batch_next_state).detach().max(1)[0]\n",
    "    expected_q_values=batch_reward+(Discount_Factor*max_next_q_values)\n",
    "   # print(\"expected_q_values=\",expected_q_values)\n",
    "    loss=F.smooth_l1_loss(current_q_values,expected_q_values)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.FloatTensor(episode_durations)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(Episodes):\n",
    "    run_episode(e, env)\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
