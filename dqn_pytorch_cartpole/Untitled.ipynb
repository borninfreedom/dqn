{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple/\n",
      "Requirement already satisfied: gym in ./lib/python3.7/site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in ./lib/python3.7/site-packages (from gym) (1.19.4)\n",
      "Requirement already satisfied: Pillow<=7.2.0 in ./lib/python3.7/site-packages (from gym) (7.2.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in ./lib/python3.7/site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: scipy in ./lib/python3.7/site-packages (from gym) (1.5.4)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in ./lib/python3.7/site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: future in ./lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in ./lib/python3.7/site-packages (from gym) (1.19.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/yan/myProjects/dqn/dqn_pytorch_cartpole/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.douban.com/simple/\n",
      "Collecting pyreadline\n",
      "  Downloading https://pypi.doubanio.com/packages/bc/7c/d724ef1ec3ab2125f38a1d53285745445ec4a8f19b9bb0761b4064316679/pyreadline-2.1.zip (109 kB)\n",
      "\u001b[K     |████████████████████████████████| 109 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyreadline\n",
      "  Building wheel for pyreadline (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyreadline: filename=pyreadline-2.1-py3-none-any.whl size=93833 sha256=fbb3bab4ffd8c460c8fac5e615f0a771528bb3b517e0df7b00cc3ef646eb24fb\n",
      "  Stored in directory: /home/yan/.cache/pip/wheels/79/8c/4f/6bc9a8aa98e0cad9e4af06bb0fcb2c8e31afebb4c71edb13a7\n",
      "Successfully built pyreadline\n",
      "Installing collected packages: pyreadline\n",
      "Successfully installed pyreadline-2.1\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/yan/myProjects/dqn/dqn_pytorch_cartpole/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gym\n",
    "%pip install pyreadline\n",
    "%config Completer.use_jedi = False\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy\n",
    "import random\n",
    "from gym import wrappers\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "Env_Name='CartPole-v0'\n",
    "\n",
    "Batch_Size=3\n",
    "Replay_Memory_Size=10000\n",
    "Target_Network_Update_Frequency=10000\n",
    "Discount_Factor=0.99\n",
    "Learning_Rate=0.00025\n",
    "Initial_Exploration=1\n",
    "Final_Exploration=0.1\n",
    "Exploration_Decay=200\n",
    "Episodes=500\n",
    "Hidden_Layer_Size=256\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device=\",device)\n",
    "\n",
    "env=gym.make(Env_Name)\n",
    "#env=wrappers.Monitor(env,'./tmp/cartpole-v1-1',force=True)\n",
    "#observation=env.reset()\n",
    "\n",
    "Input_Shape=env.observation_space.shape[0]\n",
    "Action_Shape=env.action_space.n\n",
    "#print('Input Shape=',Input_Shape)\n",
    "#print('Action Shape=',Action_Shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self,capacity):\n",
    "        self.capacity=capacity\n",
    "        self.memory=[]\n",
    "    def push(self,transition):\n",
    "        self.memory.append(transition)\n",
    "        if len(self.memory)>self.capacity:\n",
    "            del self.memory[0]\n",
    "    def sample(self,batch_size):\n",
    "        return random.sample(self.memory,batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self,input_shape=4,hidden_layer_shape=Hidden_Layer_Size,action_shape=2):\n",
    "        super(DQN,self).__init__()\n",
    "        self.l1=nn.Linear(input_shape,hidden_layer_shape)\n",
    "        self.l2=nn.Linear(hidden_layer_shape,action_shape)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.l1(x))\n",
    "        x=self.l2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=DQN(input_shape=Input_Shape,hidden_layer_shape=Hidden_Layer_Size,action_shape=Action_Shape).to(device)\n",
    "\n",
    "\n",
    "memory=ReplayMemory(Replay_Memory_Size)\n",
    "optimizer=optim.Adam(model.parameters(),Learning_Rate)\n",
    "steps_done=0\n",
    "episode_durations=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample=random.random()\n",
    "    eps_threshold=Final_Exploration+(Initial_Exploration-Final_Exploration)*math.exp(-1.*steps_done/\n",
    "                                                                                     Exploration_Decay)\n",
    "    steps_done+=1\n",
    "    if sample>eps_threshold:\n",
    "        return  model(torch.tensor(state,dtype=torch.float32).to(device)).detach().max(1)[1].view(1,1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(2)]],dtype=torch.int64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_episode(e,env):\n",
    "    state=env.reset()\n",
    "    steps=0\n",
    "    while True:\n",
    "        env.render()\n",
    "        action=select_action(torch.tensor([state],dtype=torch.float32))\n",
    "        next_state,reward,done,_=env.step(action[0,0].item())\n",
    "\n",
    "        if done:\n",
    "            reward=-1\n",
    "\n",
    "        memory.push((torch.tensor([state],dtype=torch.float32).to(device),\n",
    "                    torch.tensor(action,dtype=torch.int64).to(device),\n",
    "                    torch.tensor([next_state],dtype=torch.float32).to(device),\n",
    "                    torch.tensor([reward],dtype=torch.float32).to(device)))\n",
    "        #learn()\n",
    "        state=next_state\n",
    "        steps+=1\n",
    "        if done:\n",
    "            print(\"{2} Episode {0} finished after {1} steps\".format(e,steps,'\\033[92m' if steps>=195\n",
    "                                                                    else '\\033[99m'))\n",
    "            episode_durations.append(steps)\n",
    "           # plot_duration()\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Replay_Memory_Size\n",
    "Batch_Size\n",
    "memory.memory=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 0 finished after 10 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for e in range(1):\n",
    "    run_episode(e,env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memory.memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[ 0.1467,  0.9922, -0.1857, -1.5949]]),\n",
       "  tensor([[0]]),\n",
       "  tensor([[ 0.1666,  0.7997, -0.2175, -1.3654]]),\n",
       "  tensor([-1.])),\n",
       " (tensor([[ 0.0361,  0.7925, -0.0183, -1.1779]]),\n",
       "  tensor([[1]]),\n",
       "  tensor([[ 0.0520,  0.9879, -0.0418, -1.4762]]),\n",
       "  tensor([1.])),\n",
       " (tensor([[ 0.0161,  0.4024,  0.0114, -0.5959]]),\n",
       "  tensor([[1]]),\n",
       "  tensor([[ 2.4198e-02,  5.9739e-01, -5.6727e-04, -8.8499e-01]]),\n",
       "  tensor([1.]))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions=memory.sample(Batch_Size)\n",
    "transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[ 0.1467,  0.9922, -0.1857, -1.5949]]),\n",
       "  tensor([[ 0.0361,  0.7925, -0.0183, -1.1779]]),\n",
       "  tensor([[ 0.0161,  0.4024,  0.0114, -0.5959]])),\n",
       " (tensor([[0]]), tensor([[1]]), tensor([[1]])),\n",
       " (tensor([[ 0.1666,  0.7997, -0.2175, -1.3654]]),\n",
       "  tensor([[ 0.0520,  0.9879, -0.0418, -1.4762]]),\n",
       "  tensor([[ 2.4198e-02,  5.9739e-01, -5.6727e-04, -8.8499e-01]])),\n",
       " (tensor([-1.]), tensor([1.]), tensor([1.])))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_state,batch_action,batch_next_state,batch_reward=zip(*transitions)\n",
    "batch_state,batch_action,batch_next_state,batch_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_state= tensor([[ 0.1467,  0.9922, -0.1857, -1.5949],\n",
      "        [ 0.0361,  0.7925, -0.0183, -1.1779],\n",
      "        [ 0.0161,  0.4024,  0.0114, -0.5959]])\n",
      "batch_action= tensor([[0],\n",
      "        [1],\n",
      "        [1]])\n",
      "batch_next_state= tensor([[ 1.6656e-01,  7.9974e-01, -2.1755e-01, -1.3654e+00],\n",
      "        [ 5.1996e-02,  9.8788e-01, -4.1824e-02, -1.4762e+00],\n",
      "        [ 2.4198e-02,  5.9739e-01, -5.6727e-04, -8.8499e-01]])\n",
      "batch_reward= tensor([-1.,  1.,  1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "batch_state=torch.tensor(torch.cat(batch_state))\n",
    "batch_action=torch.tensor(torch.cat((batch_action)))\n",
    "batch_next_state=torch.tensor(torch.cat((batch_next_state)))\n",
    "batch_reward=torch.tensor(torch.cat((batch_reward)))\n",
    "print(\"batch_state=\",batch_state)\n",
    "print(\"batch_action=\",batch_action)\n",
    "print(\"batch_next_state=\",batch_next_state)\n",
    "print(\"batch_reward=\",batch_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_output= tensor([[-0.2217,  0.0603],\n",
      "        [-0.1772,  0.0315],\n",
      "        [-0.1441,  0.0161]], grad_fn=<AddmmBackward>)\n",
      "batch_action= tensor([[0],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "model_output=model(batch_state)\n",
    "print(\"model_output=\",model_output)\n",
    "print(\"batch_action=\",batch_action)\n",
    "#print(\"q=\",current_q_values.gather(1,batch_action))\n",
    "#print(\"current_q_values=\",current_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_q_values=torch.gather(model_output,1,batch_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_q_values= tensor([[-0.2217],\n",
      "        [ 0.0315],\n",
      "        [ 0.0161]], grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(\"current_q_values=\",current_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2217,  0.0603],\n",
       "        [-0.1772,  0.0315],\n",
       "        [-0.1441,  0.0161]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentq=model_output.gather(1,batch_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2217],\n",
       "        [ 0.0315],\n",
       "        [ 0.0161]], grad_fn=<GatherBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1467,  0.9922, -0.1857, -1.5949],\n",
       "        [ 0.0361,  0.7925, -0.0183, -1.1779],\n",
       "        [ 0.0161,  0.4024,  0.0114, -0.5959]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2217,  0.0603],\n",
       "        [-0.1772,  0.0315],\n",
       "        [-0.1441,  0.0161]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch_state).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.0603, 0.0315, 0.0161]),\n",
       "indices=tensor([1, 1, 1]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch_state).detach().max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0603, 0.0315, 0.0161])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch_state).detach().max(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (l1): Linear(in_features=4, out_features=256, bias=True)\n",
       "  (l2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-20b0bbb4fbc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mo' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
