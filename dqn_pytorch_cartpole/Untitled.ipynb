{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy\n",
    "import random\n",
    "from gym import wrappers\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cuda\n"
     ]
    }
   ],
   "source": [
    "Env_Name='CartPole-v0'\n",
    "\n",
    "Batch_Size=3\n",
    "Replay_Memory_Size=10000\n",
    "Target_Network_Update_Frequency=10000\n",
    "Discount_Factor=0.99\n",
    "Learning_Rate=0.00025\n",
    "Initial_Exploration=1\n",
    "Final_Exploration=0.1\n",
    "Exploration_Decay=200\n",
    "Episodes=500\n",
    "Hidden_Layer_Size=256\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device=\",device)\n",
    "\n",
    "env=gym.make(Env_Name)\n",
    "#env=wrappers.Monitor(env,'./tmp/cartpole-v1-1',force=True)\n",
    "#observation=env.reset()\n",
    "\n",
    "Input_Shape=env.observation_space.shape[0]\n",
    "Action_Shape=env.action_space.n\n",
    "#print('Input Shape=',Input_Shape)\n",
    "#print('Action Shape=',Action_Shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self,capacity):\n",
    "        self.capacity=capacity\n",
    "        self.memory=[]\n",
    "    def push(self,transition):\n",
    "        self.memory.append(transition)\n",
    "        if len(self.memory)>self.capacity:\n",
    "            del self.memory[0]\n",
    "    def sample(self,batch_size):\n",
    "        return random.sample(self.memory,batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self,input_shape=4,hidden_layer_shape=Hidden_Layer_Size,action_shape=2):\n",
    "        super(DQN,self).__init__()\n",
    "        self.l1=nn.Linear(input_shape,hidden_layer_shape)\n",
    "        self.l2=nn.Linear(hidden_layer_shape,action_shape)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.l1(x))\n",
    "        x=self.l2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=DQN(input_shape=Input_Shape,hidden_layer_shape=Hidden_Layer_Size,action_shape=Action_Shape).to(device)\n",
    "\n",
    "\n",
    "memory=ReplayMemory(Replay_Memory_Size)\n",
    "optimizer=optim.Adam(model.parameters(),Learning_Rate)\n",
    "steps_done=0\n",
    "episode_durations=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample=random.random()\n",
    "    eps_threshold=Final_Exploration+(Initial_Exploration-Final_Exploration)*math.exp(-1.*steps_done/\n",
    "                                                                                     Exploration_Decay)\n",
    "    steps_done+=1\n",
    "    if sample>eps_threshold:\n",
    "        return  model(torch.tensor(state,dtype=torch.float32).to(device)).detach().max(1)[1].view(1,1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(2)]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_episode(e,env):\n",
    "    state=env.reset()\n",
    "    steps=0\n",
    "    while True:\n",
    "        env.render()\n",
    "        action=select_action(torch.tensor([state],dtype=torch.float32))\n",
    "        next_state,reward,done,_=env.step(action[0,0].item())\n",
    "\n",
    "        if done:\n",
    "            reward=-1\n",
    "\n",
    "        memory.push((torch.tensor([state],dtype=torch.float32).to(device),\n",
    "                    torch.tensor(action,dtype=torch.float32).to(device),\n",
    "                    torch.tensor([next_state],dtype=torch.float32).to(device),\n",
    "                    torch.tensor([reward],dtype=torch.float32).to(device)))\n",
    "        #learn()\n",
    "        state=next_state\n",
    "        steps+=1\n",
    "        if done:\n",
    "            print(\"{2} Episode {0} finished after {1} steps\".format(e,steps,'\\033[92m' if steps>=195\n",
    "                                                                    else '\\033[99m'))\n",
    "            episode_durations.append(steps)\n",
    "           # plot_duration()\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Replay_Memory_Size\n",
    "Batch_Size\n",
    "memory.memory=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/myProjects/dqn_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/home/dell/myProjects/dqn_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 0 finished after 28 steps\n"
     ]
    }
   ],
   "source": [
    "for e in range(1):\n",
    "    run_episode(e,env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memory.memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[ 0.0064, -0.0092, -0.0493,  0.0203]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[ 0.0062,  0.1866, -0.0489, -0.2875]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0062,  0.1866, -0.0489, -0.2875]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[ 0.0100, -0.0078, -0.0546, -0.0106]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0100, -0.0078, -0.0546, -0.0106]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[ 0.0098, -0.2021, -0.0549,  0.2643]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0098, -0.2021, -0.0549,  0.2643]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[ 0.0058, -0.0062, -0.0496, -0.0452]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0058, -0.0062, -0.0496, -0.0452]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[ 0.0056,  0.1896, -0.0505, -0.3531]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0056,  0.1896, -0.0505, -0.3531]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[ 0.0094, -0.0048, -0.0575, -0.0767]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0094, -0.0048, -0.0575, -0.0767]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[ 0.0093, -0.1990, -0.0591,  0.1973]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0093, -0.1990, -0.0591,  0.1973]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[ 0.0053, -0.0031, -0.0551, -0.1134]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0053, -0.0031, -0.0551, -0.1134]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[ 0.0053,  0.1927, -0.0574, -0.4230]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0053,  0.1927, -0.0574, -0.4230]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[ 0.0091, -0.0015, -0.0659, -0.1489]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0091, -0.0015, -0.0659, -0.1489]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[ 0.0091, -0.1957, -0.0688,  0.1223]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0091, -0.1957, -0.0688,  0.1223]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[ 0.0052, -0.3897, -0.0664,  0.3925]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0052, -0.3897, -0.0664,  0.3925]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[-0.0026, -0.1937, -0.0585,  0.0796]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0026, -0.1937, -0.0585,  0.0796]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[-0.0065, -0.3880, -0.0569,  0.3533]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0065, -0.3880, -0.0569,  0.3533]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[-0.0142, -0.5822, -0.0499,  0.6275]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0142, -0.5822, -0.0499,  0.6275]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[-0.0259, -0.3864, -0.0373,  0.3195]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0259, -0.3864, -0.0373,  0.3195]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[-0.0336, -0.1908, -0.0309,  0.0153]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0336, -0.1908, -0.0309,  0.0153]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[-0.0374,  0.0047, -0.0306, -0.2870]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0374,  0.0047, -0.0306, -0.2870]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[-0.0373,  0.2003, -0.0364, -0.5892]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0373,  0.2003, -0.0364, -0.5892]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[-0.0333,  0.0057, -0.0482, -0.3082]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0333,  0.0057, -0.0482, -0.3082]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[-0.0332,  0.2015, -0.0543, -0.6157]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0332,  0.2015, -0.0543, -0.6157]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[-0.0292,  0.3973, -0.0666, -0.9249]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0292,  0.3973, -0.0666, -0.9249]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[-0.0212,  0.2031, -0.0851, -0.6539]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0212,  0.2031, -0.0851, -0.6539]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[-0.0172,  0.3993, -0.0982, -0.9722]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0172,  0.3993, -0.0982, -0.9722]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[-0.0092,  0.5956, -0.1177, -1.2940]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0092,  0.5956, -0.1177, -1.2940]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[ 0.0027,  0.7920, -0.1435, -1.6211]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0027,  0.7920, -0.1435, -1.6211]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[ 0.0186,  0.9885, -0.1760, -1.9548]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[ 0.0186,  0.9885, -0.1760, -1.9548]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[ 0.0383,  1.1850, -0.2151, -2.2965]], device='cuda:0'),\n",
       "  tensor([-1.], device='cuda:0'))]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[ 0.0062,  0.1866, -0.0489, -0.2875]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[ 0.0100, -0.0078, -0.0546, -0.0106]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0092,  0.5956, -0.1177, -1.2940]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[ 0.0027,  0.7920, -0.1435, -1.6211]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')),\n",
       " (tensor([[-0.0065, -0.3880, -0.0569,  0.3533]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[-0.0142, -0.5822, -0.0499,  0.6275]], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0'))]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions=memory.sample(Batch_Size)\n",
    "transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[ 0.0062,  0.1866, -0.0489, -0.2875]], device='cuda:0'),\n",
       "  tensor([[-0.0092,  0.5956, -0.1177, -1.2940]], device='cuda:0'),\n",
       "  tensor([[-0.0065, -0.3880, -0.0569,  0.3533]], device='cuda:0')),\n",
       " (tensor([[0.]], device='cuda:0'),\n",
       "  tensor([[1.]], device='cuda:0'),\n",
       "  tensor([[0.]], device='cuda:0')),\n",
       " (tensor([[ 0.0100, -0.0078, -0.0546, -0.0106]], device='cuda:0'),\n",
       "  tensor([[ 0.0027,  0.7920, -0.1435, -1.6211]], device='cuda:0'),\n",
       "  tensor([[-0.0142, -0.5822, -0.0499,  0.6275]], device='cuda:0')),\n",
       " (tensor([1.], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0'),\n",
       "  tensor([1.], device='cuda:0')))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_state,batch_action,batch_next_state,batch_reward=zip(*transitions)\n",
    "batch_state,batch_action,batch_next_state,batch_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.], device='cuda:0'),\n",
       " tensor([1.], device='cuda:0'),\n",
       " tensor([1.], device='cuda:0'))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(batch_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.cat(batch_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/myProjects/dqn_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(torch.cat(batch_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_state= tensor([[ 0.0062,  0.1866, -0.0489, -0.2875],\n",
      "        [-0.0092,  0.5956, -0.1177, -1.2940],\n",
      "        [-0.0065, -0.3880, -0.0569,  0.3533]], device='cuda:0')\n",
      "batch_action= tensor([[0.],\n",
      "        [1.],\n",
      "        [0.]], device='cuda:0')\n",
      "batch_next_state= tensor([[ 0.0100, -0.0078, -0.0546, -0.0106],\n",
      "        [ 0.0027,  0.7920, -0.1435, -1.6211],\n",
      "        [-0.0142, -0.5822, -0.0499,  0.6275]], device='cuda:0')\n",
      "batch_reward= tensor([1., 1., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dell/myProjects/dqn_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/dell/myProjects/dqn_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/dell/myProjects/dqn_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/dell/myProjects/dqn_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "batch_state=torch.tensor(torch.cat(batch_state))\n",
    "batch_action=torch.tensor(torch.cat((batch_action)))\n",
    "batch_next_state=torch.tensor(torch.cat((batch_next_state)))\n",
    "batch_reward=torch.tensor(torch.cat((batch_reward)))\n",
    "print(\"batch_state=\",batch_state)\n",
    "print(\"batch_action=\",batch_action)\n",
    "print(\"batch_next_state=\",batch_next_state)\n",
    "print(\"batch_reward=\",batch_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_action= tensor([[0.],\n",
      "        [1.],\n",
      "        [0.]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "gather_out_cuda(): Expected dtype int64 for index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-97f2c72d4aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcurrent_q_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_action=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_q_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"current_q_values=\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_q_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: gather_out_cuda(): Expected dtype int64 for index"
     ]
    }
   ],
   "source": [
    "current_q_values=model(batch_state)\n",
    "print(\"batch_action=\",batch_action)\n",
    "print(\"q=\",current_q_values.gather(1,batch_action))\n",
    "print(\"current_q_values=\",current_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
