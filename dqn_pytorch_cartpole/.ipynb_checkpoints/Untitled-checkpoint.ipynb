{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.douban.com/simple/\n",
      "Requirement already satisfied: gym in ./lib/python3.7/site-packages (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in ./lib/python3.7/site-packages (from gym) (1.19.4)\n",
      "Requirement already satisfied: Pillow<=7.2.0 in ./lib/python3.7/site-packages (from gym) (7.2.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in ./lib/python3.7/site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in ./lib/python3.7/site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: scipy in ./lib/python3.7/site-packages (from gym) (1.5.4)\n",
      "Requirement already satisfied: future in ./lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in ./lib/python3.7/site-packages (from gym) (1.19.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/yan/myProjects/dqn/dqn_pytorch_cartpole/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gym\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy\n",
    "import random\n",
    "from gym import wrappers\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "Env_Name='CartPole-v0'\n",
    "\n",
    "Batch_Size=3\n",
    "Replay_Memory_Size=10000\n",
    "Target_Network_Update_Frequency=10000\n",
    "Discount_Factor=0.99\n",
    "Learning_Rate=0.00025\n",
    "Initial_Exploration=1\n",
    "Final_Exploration=0.1\n",
    "Exploration_Decay=200\n",
    "Episodes=500\n",
    "Hidden_Layer_Size=256\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device=\",device)\n",
    "\n",
    "env=gym.make(Env_Name)\n",
    "#env=wrappers.Monitor(env,'./tmp/cartpole-v1-1',force=True)\n",
    "#observation=env.reset()\n",
    "\n",
    "Input_Shape=env.observation_space.shape[0]\n",
    "Action_Shape=env.action_space.n\n",
    "#print('Input Shape=',Input_Shape)\n",
    "#print('Action Shape=',Action_Shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self,capacity):\n",
    "        self.capacity=capacity\n",
    "        self.memory=[]\n",
    "    def push(self,transition):\n",
    "        self.memory.append(transition)\n",
    "        if len(self.memory)>self.capacity:\n",
    "            del self.memory[0]\n",
    "    def sample(self,batch_size):\n",
    "        return random.sample(self.memory,batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self,input_shape=4,hidden_layer_shape=Hidden_Layer_Size,action_shape=2):\n",
    "        super(DQN,self).__init__()\n",
    "        self.l1=nn.Linear(input_shape,hidden_layer_shape)\n",
    "        self.l2=nn.Linear(hidden_layer_shape,action_shape)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.l1(x))\n",
    "        x=self.l2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=DQN(input_shape=Input_Shape,hidden_layer_shape=Hidden_Layer_Size,action_shape=Action_Shape).to(device)\n",
    "\n",
    "\n",
    "memory=ReplayMemory(Replay_Memory_Size)\n",
    "optimizer=optim.Adam(model.parameters(),Learning_Rate)\n",
    "steps_done=0\n",
    "episode_durations=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample=random.random()\n",
    "    eps_threshold=Final_Exploration+(Initial_Exploration-Final_Exploration)*math.exp(-1.*steps_done/\n",
    "                                                                                     Exploration_Decay)\n",
    "    steps_done+=1\n",
    "    if sample>eps_threshold:\n",
    "        return  model(torch.tensor(state,dtype=torch.float32).to(device)).detach().max(1)[1].view(1,1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(2)]],dtype=torch.int64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_episode(e,env):\n",
    "    state=env.reset()\n",
    "    steps=0\n",
    "    while True:\n",
    "        env.render()\n",
    "        action=select_action(torch.tensor([state],dtype=torch.float32))\n",
    "        next_state,reward,done,_=env.step(action[0,0].item())\n",
    "\n",
    "        if done:\n",
    "            reward=-1\n",
    "\n",
    "        memory.push((torch.tensor([state],dtype=torch.float32).to(device),\n",
    "                    torch.tensor(action,dtype=torch.int64).to(device),\n",
    "                    torch.tensor([next_state],dtype=torch.float32).to(device),\n",
    "                    torch.tensor([reward],dtype=torch.float32).to(device)))\n",
    "        #learn()\n",
    "        state=next_state\n",
    "        steps+=1\n",
    "        if done:\n",
    "            print(\"{2} Episode {0} finished after {1} steps\".format(e,steps,'\\033[92m' if steps>=195\n",
    "                                                                    else '\\033[99m'))\n",
    "            episode_durations.append(steps)\n",
    "           # plot_duration()\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Replay_Memory_Size\n",
    "Batch_Size\n",
    "memory.memory=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 0 finished after 31 steps\n"
     ]
    }
   ],
   "source": [
    "for e in range(1):\n",
    "    run_episode(e,env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "memory.memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[ 0.0214, -0.2306, -0.0289,  0.2485]]),\n",
       "  tensor([[0]]),\n",
       "  tensor([[ 0.0168, -0.4253, -0.0239,  0.5319]]),\n",
       "  tensor([1.])),\n",
       " (tensor([[-0.0045,  0.3568, -0.0254, -0.6739]]),\n",
       "  tensor([[1]]),\n",
       "  tensor([[ 0.0026,  0.5522, -0.0389, -0.9745]]),\n",
       "  tensor([1.])),\n",
       " (tensor([[-0.0048, -0.2295,  0.0018,  0.2249]]),\n",
       "  tensor([[1]]),\n",
       "  tensor([[-0.0094, -0.0344,  0.0063, -0.0672]]),\n",
       "  tensor([1.]))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions=memory.sample(Batch_Size)\n",
    "transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[ 0.0214, -0.2306, -0.0289,  0.2485]]),\n",
       "  tensor([[-0.0045,  0.3568, -0.0254, -0.6739]]),\n",
       "  tensor([[-0.0048, -0.2295,  0.0018,  0.2249]])),\n",
       " (tensor([[0]]), tensor([[1]]), tensor([[1]])),\n",
       " (tensor([[ 0.0168, -0.4253, -0.0239,  0.5319]]),\n",
       "  tensor([[ 0.0026,  0.5522, -0.0389, -0.9745]]),\n",
       "  tensor([[-0.0094, -0.0344,  0.0063, -0.0672]])),\n",
       " (tensor([1.]), tensor([1.]), tensor([1.])))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_state,batch_action,batch_next_state,batch_reward=zip(*transitions)\n",
    "batch_state,batch_action,batch_next_state,batch_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_state= tensor([[ 0.0214, -0.2306, -0.0289,  0.2485],\n",
      "        [-0.0045,  0.3568, -0.0254, -0.6739],\n",
      "        [-0.0048, -0.2295,  0.0018,  0.2249]])\n",
      "batch_action= tensor([[0],\n",
      "        [1],\n",
      "        [1]])\n",
      "batch_next_state= tensor([[ 0.0168, -0.4253, -0.0239,  0.5319],\n",
      "        [ 0.0026,  0.5522, -0.0389, -0.9745],\n",
      "        [-0.0094, -0.0344,  0.0063, -0.0672]])\n",
      "batch_reward= tensor([1., 1., 1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/yan/myProjects/dqn/dqn_pytorch_cartpole/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "batch_state=torch.tensor(torch.cat(batch_state))\n",
    "batch_action=torch.tensor(torch.cat((batch_action)))\n",
    "batch_next_state=torch.tensor(torch.cat((batch_next_state)))\n",
    "batch_reward=torch.tensor(torch.cat((batch_reward)))\n",
    "print(\"batch_state=\",batch_state)\n",
    "print(\"batch_action=\",batch_action)\n",
    "print(\"batch_next_state=\",batch_next_state)\n",
    "print(\"batch_reward=\",batch_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_output= tensor([[0.1984, 0.1787],\n",
      "        [0.2036, 0.0406],\n",
      "        [0.1972, 0.1749]], grad_fn=<AddmmBackward>)\n",
      "batch_action= tensor([[0],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "model_output=model(batch_state)\n",
    "print(\"model_output=\",model_output)\n",
    "print(\"batch_action=\",batch_action)\n",
    "#print(\"q=\",current_q_values.gather(1,batch_action))\n",
    "#print(\"current_q_values=\",current_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_q_values=torch.gather(model_output,1,batch_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_q_values= tensor([[0.1984],\n",
      "        [0.0406],\n",
      "        [0.1749]], grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(\"current_q_values=\",current_q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1984, 0.1787],\n",
       "        [0.2036, 0.0406],\n",
       "        [0.1972, 0.1749]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentq=model_output.gather(1,batch_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1984],\n",
       "        [0.0406],\n",
       "        [0.1749]], grad_fn=<GatherBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
