# 课程大纲
* 要想实现倒立摆，可以让算法能解决cartpole问题，所以首先根据dqn的论文编写dqn算法的代码，使之解决cartpole问题
* 编写倒立摆的环境代码，即动力学方程、奖励函数、状态转移等规则
* 将dqn代码应用到倒立摆问题，结果在博客中已经看到了，并不能解决倒立摆问题，然后使用stable baselines的dqn算法（不需要自己从头编写算法）来尝试解决，同样会是失败的结果
* 使用stable baselines的PPO算法（PPO是目前各大机构愿意使用的，性能较好的算法，算法简单但是效果很好，同样不需要自己从头编写算法）来解决倒立摆，结果是成功
* 因为上面自己编写倒立摆的环境，其中包含动力学方程，这并没有看出和使用常规方法的优势，所以在pybullet仿真软件中封装这个环境，动力学的计算交给bullet3引擎来计算，自己编程只负责剩下的较为简单的部分，这就体现出了使用强化学习方法的优势，即不需要考虑动力学，让非控制专业人员也能解决控制问题。
* 将PPO算法再应用到pybullet上封装的环境中
* 介绍一下使用强化学习来解决机器人问题的常规步骤，只要包括使用仿真软件来负责动力学的部分，剩下的简单部分自己编写，即做到了非专业人员可以做专业的事情这个优势
